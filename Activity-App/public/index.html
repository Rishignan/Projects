<!DOCTYPE html>
<html lang="en">


<head>


	<meta charset="UTF-8">
	<title>Machine Learning</title>
	<link rel="stylesheet" href="style.css">
	
	
</head>


	<body>
	
		<div id='container'>
		
		

		<header>
			
			<h1> Machine Learning</h1>
		</header>
		
		<aside>
			
			<h2>Share Your Favorite </h2>
			<h3>Share Your Favorite ways to use machine learning </h3>
			
			<form action="/comments" method="POST">
					
					<input type="text" name="name" placeholder="First Name"/>
					<textarea name="comment" id="" cols="30" rows="10" placeholder="Enter your Favorite use of Machine learning in present days"></textarea> 
					
					<input type="submit" value="Submit"/>
					
					<section id="suggestions">
			<h2>Comments</h2>
		</section>
					
				</form>
				
				
			 
		
			
			
		</aside>
		
		<article>
			
			<h2>All about machine learning</h2>
			<p>Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use in order to perform a specific task effectively without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as "training data", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory data analysis through unsupervised learning.In its application across business problems, machine learning is also referred to as predictive analytics.</p>
			
			<img src="ml.jpg" alt="" width="500px" height="300px">
			<!--add a machine learning image here-->
				
			
			<h3>DIFFERENT MACHINE LEARNING APPROACHES</h3>
			
			
			<ul>
				<h4>TYPES OF LEARNING ALGORITHMS</h4>
				<li>Supervised learning --> <a href="https://www.geeksforgeeks.org/ml-types-learning-supervised-learning/">Learn More :)</a></li>
				<li>Unsupervised learning --> <a href="https://www.datarobot.com/wiki/unsupervised-machine-learning/">Learn More :)</a></li>
				<li>Reinforcement learning --> <a href="https://www.geeksforgeeks.org/what-is-reinforcement-learning/">Learn More :)</a> </li>
				
				<li>Feature learning --> <a href="https://en.wikipedia.org/wiki/Feature_learning">Learn More :)</a> </li>
				
				<li>Sparse dictionary learning -->  <a href="https://en.wikipedia.org/wiki/Sparse_dictionary_learning">Learn More :)</a></li>
				<li>Anomaly detection --> <a href="https://www.datascience.com/blog/python-anomaly-detection">Learn More :)</a></li>
				
				<li>Association rules --> <a href="https://en.wikipedia.org/wiki/Association_rule_learning">Learn More :)</a></li>
				
			</ul>
			
			
			<ul>
				<h4>TYPES OF MODELS : Do you want to know in depth ? --> <a href="https://en.wikipedia.org/wiki/Machine_learning#Models">Click Me</a></h4>
				
				<li>Artificial neural networks</li>
				
				<li>Decision trees</li>
				
				<li>Support vector machines</li>
				
				<li>Bayesian networks</li>
				
				<li>Genetic algorithms</li>
				
				
			</ul>
			
			
			
			<ul>
				<h4>TRAINING MODELS : For more Information --> <a href="https://en.wikipedia.org/wiki/Machine_learning#Training_models">Click Me</a></h4>
				<li>Federated learning </li>
				
				
			</ul>
			
			
			
			<h3>APPLICATIONS OF MACHINE LEARNING</h3>
			<p>Machine learning is one of the most exciting technologies that one would have ever come across. As it is evident from the name, it gives the computer that which makes it more similar to humans: The ability to learn. Machine learning is actively being used today, perhaps in many more places than one would expect. We probably use a learning algorithm dozens of time without even knowing it.</p>
			
			<h4>Applications of Machine Learning include:</h4>
			<ul>
				
				<li style="font-weight: bold">Web Search Engine: </li>
				
				<p>One of the reasons why search engines like google, bing etc work so well is because the system has learnt how to rank pages through a complex learning algorithm. </p>
				
				<li style="font-weight: bold">Photo tagging Applications:</li>
				
				<p>Be it facebook or any other photo tagging application, the ability to tag friends makes it even more happening. It is all possible because of a face recognition algorithm that runs behind the application.</p>
				
				<li style="font-weight: bold">Spam Detector:</li>
				
				<p> Our mail agent like Gmail or Hotmail does a lot of hard work for us in classifying the mails and moving the spam mails to spam folder. This is again achieved by a spam classifier running in the back end of mail application </p>
				
				<a href="https://www.geeksforgeeks.org/machine-learning-introduction/">For more Information</a>
				
				
				
				
			</ul>
			
			<h3>TOP 5 LIMITATIONS OF MACHINE LEARNING</h3>
			<p>Astounding technological breakthroughs in the field of Artificial Intelligence (AI) and its sub-field Machine Learning (ML) have been made in the last couple of years. Machines can now be trained to behave like humans enabling them to mimic complex cognitive functions like informed decision-making, deductive reasoning, and inferences. Robots behaving like humans is no longer science fiction, but a reality in multiple industry practices today. As a matter of fact, human society is gradually becoming more reliant on smart machines to solve day to day challenges and make decisions. A good example of a simple use case for machine learning that has completely permeated our day-to-day lives is spam filters, which intrinsically determine whether a message is junk based on how closely it matches emails with a similar tag.</p>
			
			<p>However, these basic applications have evolved into ‘deep learning’ enabling software to complete complex tasks with significant implications for the way business is conducted. In all the hype surrounding these game-changing technologies, the reality that often times gets lost amidst both the fears and the headline victories like Cortana, Alexa, Google Duplex, Waymo, and AlphaGo, is that AI technologies have several limitations that will still need a substantial amount of effort to overcome. This post explores some of those limitations.</p>
			
			<h4>Applications of Machine Learning include:</h4>
			<ul>
				
				<li style="font-weight: bold">Machine Learning Algorithms Require Massive Stores of Training Data </li>
				
				<p>AI systems are ‘trained’, not programmed. This means that they require enormous amounts of data to perform complex tasks at the level of humans. Despite the fact that data is being created at an accelerated pace and the robust computing power needed to efficiently process it is available; massive data sets are not simple to create or obtain for most business use cases. Deep learning utilizes an algorithm called backpropagation that adjusts the weights between nodes, to ensure an input translates to the right output. Supervised learning occurs when neural nets are trained to recognize photographs, for example, using millions or billions of previous labeled examples. And every slight variation in an assigned task calls for another large data set to conduct additional training. The major limitation is that neural networks simply require too much ‘brute force’ to function at a level similar to human intellect.</p>
				
				
				
				<li style="font-weight: bold">Labeling Training Data Is a Tedious Process</li>  <p>Supervised machine learning using deep neural networks forms the basis for AI. Labeling is a requisite stage of data processing in supervised learning. This model training style utilizes predefined target attributes from historical data. Data labeling is simply the process of cleaning up raw data and organizing it for cognitive systems (machines) to ingest. Deep learning requires lots of labeled data, and while labeling is not rocket science, it is still a complex task to complete. If unlabeled data is fed into the AI, it is not going to get smart over time. An algorithm can only develop the ability to make decisions, perceive, and behave in a way that is consistent with the environment within which it is required to navigate in the future if a human mapped target attributes for it.</p>
				
				
				
				<li style="font-weight: bold">Machines Cannot Explain Themselves</li>
				
				<p>Researchers at MIT hypothesize that the human brain has an intuitive physics engine. This basically means that the information we are able to collect via our sense is noisy and imprecise; however, we make conclusions about what we think will likely happen. For decades, common sense has been the most difficult challenge in the field of Artificial Intelligence. A large majority of AI-based models currently deployed is based on statistical machine learning that relies on tons of training data to build a statistical model. This is the main reason why adoption of some AI tools is still low in areas where explainability is crucial. A good example is in regulations such as GDPR, which requires a ‘right to explanation’.

				Whether the decision is good or bad, having visibility into how/ why it was made is crucial, so that the human expectation can be brought in line with how the algorithm actually behaves. There are techniques that can be used to interpret complicated machine learning models like neural networks. A nascent approach is Local Interpretable Model-Agnostic Explanations (LIME), which attempts to pinpoint the parts of input data a trained ML model depends on most to create predictions, by feeding inputs similar to the initial ones and observing how these predictions vary.</p>
				
				
				<li style="font-weight: bold">There is Bias in the Data</li>
				
				
				<p>As AI and machine learning algorithms are deployed, there will likely be more instances in which potential bias finds its way into algorithms and data sets. In some instances, models that are seemingly performing well maybe actually picking up noise in the data. As much as transparency is important, unbiased decision making builds trust. The infallibility of an AI solution is based on the quality of its inputs. For example, facial recognition has had a large impact on social media, human resources, law-enforcement and other applications. But biases in the data sets provided by facial recognition applications can lead to inexact outcomes. If the training data is not neutral the outcomes will inherently amplify the discrimination and bias that lies in the data set. The most ideal way to mitigate such risks is by collecting data from multiple random sources. A heterogeneous dataset limits the exposure to bias and results in higher quality ML solutions.</p>
				
				<li style="font-weight: bold">A.I Algorithms Don’t Collaborate</li>
				
				<p>Despite the multiple breakthroughs in deep learning and neural networks, AI models still lack the ability to generalize conditions that vary from the ones they encountered in training. AI models have difficulty transferring their experiences from one set of circumstances to the other. This means that anything a model has achieved for a specific use case will only be applicable to that use case. As a result, organizations are forced to continuously commit resources to train other models, even when the use cases are relatively similar. A solution to this scenario comes in the form of transfer learning. Knowledge obtained from one task can be used in situations where little labeled data is available. As this and other generalized approaches mature, organizations will have the ability to build new applications more rapidly.

				</p>
				
				
				<a href="https://en.wikipedia.org/wiki/Machine_learning#Limitations">For more Information</a>
				
				
				
				
			</ul>
			
		</article>
		
		
		
		<footer>
			
			Developed bu Rishi Avvaru.
		</footer>
		
		</div>
		
		
		

	
	
	
	
	<script src="jquery-3.4.1.min.js"></script>
	<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>

	<script src="app.js"></script>
	
	

	</body>






</html>